
For train.py: 
import sys
sys.path.insert(0, '~/venvs/env_pt12/lib/python3.8/site-packages')

data_folder_path -> '/N/project/SAIGE_shared/librispeech'


srun -p gpu -A r00105 --gpus-per-node 1 --pty bash
module load python/3.8.10

cd ~/Projects/DiffCodec

python -m srcs.train --enc_ratios 8 5 4 2 --seq_len_p_sec 5 --n_residual_layers 1 --n_filters 32 --lstm 2  --quantization --bandwidth 24 --use_disc --disc_freq 5 --final_activation Tanh --exp_name 0515_encodec_tanh_libri_test --batch_size 20 --lr 0.00005 --data_folder_path '/N/project/SAIGE_shared/librispeech'



#!/bin/bash

#SBATCH -J 0516_8_ae_self_cond
#SBATCH -p general
#SBATCH -o filename_%j.txt
#SBATCH -e filename_%j.err
#SBATCH --mail-type=ALL
#SBATCH --mail-user=hy17@iu.edu
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --time=20:00:00
#SBATCH --mem=16G
#SBATCH -A r00105

#Load any modules that your program needs
module load python/3.8.10

cd /N/u/hy17/BigRed200/Projects/DiffCodec

#Run your program
python -m srcs.train --seq_len_p_sec 0.8 --rep_dims 128 --diff_dims 256 --enc_ratios 8 --cond_enc_ratios 8 5 4 2 --n_residual_layers 1 --n_filters 32 --lstm 2 --finetune_model '/home/hy17/Projects/DiffCodec/saved_models/8_ae_tanh' --final_activation Tanh --exp_name 0517diff_8with_8542_longer --batch_size 20 --run_diff --model_type unet --seq_length 1600 --cond_quantization --cond_bandwidth 3 --debug

srun python -m srcs.train --seq_len_p_sec 0.8 --rep_dims 128 --diff_dims 256 --enc_ratios 8 --n_residual_layers 1 --n_filters 32 --lstm 2 --finetune_model '/N/u/hy17/BigRed200/Projects/DiffCodec/saved_models/0517diff_8_ae_scaling_feature_map' --exp_name 0517diff_8_ae_scaling_feature_map --scaling --batch_size 20 --run_diff --model_type unet --seq_length 1600 --data_folder_path '/N/project/SAIGE_shared/librispeech' --lr 0.00005